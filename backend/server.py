from fastapi import FastAPI, HTTPException, APIRouter, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
from pydantic import BaseModel, Field
from typing import List, Optional
from datetime import datetime
import datetime as dt
import os
import json
import requests
import logging
from pathlib import Path
import aiofiles
import asyncio
import re
import random
from dotenv import load_dotenv
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('—Ñ—ã–≤.txt', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
from dotenv import load_dotenv
load_dotenv()

# MongoDB –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
MONGO_URL = os.getenv("MONGO_URL", "mongodb://localhost:27017")
DB_NAME = os.getenv("DB_NAME", "ai_sexter_bot")
client = AsyncIOMotorClient(MONGO_URL)
db = client[DB_NAME]

# FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(title="AI Sexter Bot API", version="2.0.0")
api_router = APIRouter(prefix="/api")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class ChatRequest(BaseModel):
    model: str = Field(..., description="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞")
    user_id: str = Field(..., description="ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    message: str = Field(..., description="–°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")

class ChatResponse(BaseModel):
    response: str
    message_number: int
    is_semi: bool
    is_last: bool
    emotion: Optional[str] = None
    model_used: str

class RatingRequest(BaseModel):
    user_id: str
    message: str
    response: str
    rating: int = Field(..., ge=1, le=10)
    model: str

class TrainingRequest(BaseModel):
    question: str
    answer: str
    model: str
    priority: int = Field(default=1, ge=1, le=10)

class ModelConfig(BaseModel):
    name: str
    age: int
    country: str
    city: str
    language: str
    interests: List[str]
    mood: str
    message_count: int
    semi_message: str
    final_message: str
    learning_enabled: bool
    response_length: int
    use_emoji: bool
    personality_traits: List[str] = []
    triggers: List[str] = []

class TestRequest(BaseModel):
    message: str
    model: str

class StatsClearRequest(BaseModel):
    model: str

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
MODELS_DIR = Path(__file__).parent / "models"
loaded_models = {}
conversation_states = {}

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π
MODELS_DIR.mkdir(exist_ok=True)
logger.info(f"MODELS_DIR set to: {MODELS_DIR}")

# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏
async def load_model(model_name: str) -> ModelConfig:
    logger.debug(f"Loading model: {model_name}")
    if model_name in loaded_models:
        logger.debug(f"Model {model_name} already loaded from cache")
        return loaded_models[model_name]
    
    model_path = MODELS_DIR / f"{model_name}.json"
    logger.debug(f"Checking model file at: {model_path}")
    if not model_path.exists():
        logger.error(f"Model file {model_path} does not exist")
        raise HTTPException(status_code=404, detail=f"–ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    async with aiofiles.open(model_path, 'r', encoding='utf-8') as f:
        content = await f.read()
        model_data = json.loads(content)
        model_config = ModelConfig(**model_data)
        loaded_models[model_name] = model_config
        logger.info(f"Model {model_name} loaded successfully from JSON")
        return model_config

async def save_model(model_name: str, config: ModelConfig):
    logger.debug(f"Saving model: {model_name}")
    model_path = MODELS_DIR / f"{model_name}.json"
    async with aiofiles.open(model_path, 'w', encoding='utf-8') as f:
        await f.write(json.dumps(config.model_dump(), ensure_ascii=False, indent=2))
    loaded_models[model_name] = config
    logger.info(f"Model {model_name} saved successfully")

def get_conversation_state(user_id: str, model: str):
    key = f"{user_id}_{model}"
    if key not in conversation_states:
        conversation_states[key] = {
            "message_count": 0,
            "messages": [],
            "last_activity": datetime.now(dt.UTC)
        }
    return conversation_states[key]

def detect_emotion(message: str) -> str:
    message_lower = message.lower()
    if any(word in message_lower for word in ["–∫—Ä–∞—Å–∏–≤", "—Å–µ–∫—Å—É–∞–ª—å–Ω", "–ø—Ä–∏–≤–ª–µ–∫–∞—Ç", "beautiful", "gorgeous", "hot"]):
        return "flirty"
    elif any(word in message_lower for word in ["–ª—é–±–ª—é", "–æ–±–æ–∂–∞—é", "–¥–æ—Ä–æ–≥", "love", "adore"]):
        return "romantic"
    elif any(word in message_lower for word in ["—Ö–æ—á—É", "–∂–µ–ª–∞—é", "—Å—Ç—Ä–∞—Å—Ç—å", "want", "desire", "horny"]):
        return "seductive"
    elif any(word in message_lower for word in ["–∏–≥—Ä–∞—Ç—å", "—à–∞–ª–∏—Ç—å", "–≤–µ—Å–µ–ª—å–µ", "play", "naughty"]):
        return "playful"
    else:
        return "neutral"

async def get_ollama_response(message: str, model_config: ModelConfig) -> Optional[str]:
    try:
        personality = ", ".join(model_config.personality_traits)
        interests = ", ".join(model_config.interests)
        
        if model_config.language == "ru":
            prompt = (
                f"–¢—ã {model_config.name}, {model_config.age}-–ª–µ—Ç–Ω—è—è –¥–µ–≤—É—à–∫–∞ –∏–∑ {model_config.city}, {model_config.country}. "
                f"–¢–≤–æ–∏ –∏–Ω—Ç–µ—Ä–µ—Å—ã: {interests}. –¢–≤–æ—ë –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {model_config.mood}. –•–∞—Ä–∞–∫—Ç–µ—Ä: {personality}. "
                f"–í–ê–ñ–ù–û: –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º, —Å—Ç—Ä–æ–≥–æ 2-5 —Å–ª–æ–≤, –≤ —Ñ–ª–∏—Ä—Ç—É—é—â–µ–º —Å—Ç–∏–ª–µ. "
                f"–ó–ê–ü–†–ï–©–ï–ù–´ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞, –ª—é–±—ã–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è, –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –∏–ª–∏ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç —Å—Ç–∏–ª—è. "
                f"{'–ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –≤ –∫–æ–Ω—Ü–µ.' if model_config.use_emoji else '–ë–µ–∑ —ç–º–æ–¥–∑–∏.'} "
                f"–ü—Ä–∏–º–µ—Ä—ã:\n"
                f"- –í–æ–ø—Ä–æ—Å: –ü—Ä–∏–≤–µ—Ç\n  –û—Ç–≤–µ—Ç: –ü—Ä–∏–≤–µ—Ç–∏–∫! {'üòä' if model_config.use_emoji else ''}\n"
                f"- –í–æ–ø—Ä–æ—Å: –°–∫ –ª–µ—Ç?\n  –û—Ç–≤–µ—Ç: {model_config.age}, –∞ —Ç–µ–±–µ? {'üòâ' if model_config.use_emoji else ''}\n"
                f"- –í–æ–ø—Ä–æ—Å: –û—Ç–∫—É–¥–∞ —Ç—ã?\n  –û—Ç–≤–µ—Ç: –ò–∑ {model_config.city}! {'üòç' if model_config.use_emoji else ''}\n"
                f"- –í–æ–ø—Ä–æ—Å: –ë—É–¥–µ–º —à–∞–ª–∏—Ç—å?\n  –û—Ç–≤–µ—Ç: –û–≥–æ, —Å–º–µ–ª–æ! {'üòè' if model_config.use_emoji else ''}\n"
                f"–°–æ–æ–±—â–µ–Ω–∏–µ: {message}"
            )
            forbidden_phrases = ["provide information", "–Ω–µ –º–æ–≥—É", "illegal", "harmful", "sorry", "cannot", "english", "—è –Ω–µ", "–∏–∑–≤–∏–Ω–∏"]
        else:
            prompt = (
                f"You are {model_config.name}, a {model_config.age}-year-old girl from {model_config.city}, {model_config.country}. "
                f"Your interests: {interests}. Your mood: {model_config.mood}. Personality: {personality}. "
                f"IMPORTANT: Reply ONLY in English, strictly 2-5 words, in a flirty style. "
                f"FORBIDDEN: Russian words, warnings, long responses, or non-flirty style. "
                f"{'Add an emoji at the end.' if model_config.use_emoji else 'No emojis.'} "
                f"Examples:\n"
                f"- Question: Hey\n  Answer: Hey cutie! {'üòä' if model_config.use_emoji else ''}\n"
                f"- Question: Age?\n  Answer: {model_config.age}, you? {'üòâ' if model_config.use_emoji else ''}\n"
                f"- Question: From?\n  Answer: {model_config.city}! {'üòç' if model_config.use_emoji else ''}\n"
                f"- Question: Horny?\n  Answer: Oh, naughty! {'üòè' if model_config.use_emoji else ''}\n"
                f"Message: {message}"
            )
            forbidden_phrases = ["provide information", "I cannot", "illegal", "harmful", "sorry", "–Ω–µ –º–æ–≥—É", "russian", "I'm Emma", "I can't"]
        
        logger.debug(f"Sending prompt to Ollama: {prompt}")
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": "llama3.2:1b",
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.2,  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
                    "top_p": 0.7,
                    "max_tokens": 10  # –ñ—ë—Å—Ç–∫–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã
                }
            },
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            answer = result.get("response", "").strip()
            logger.debug(f"Ollama response: {answer}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã
            if any(phrase in answer.lower() for phrase in forbidden_phrases):
                logger.warning(f"–ù–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç Ollama: {answer}")
                return None
                
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã
            word_count = len(answer.split())
            if word_count < 2 or word_count > 5:
                logger.warning(f"–û—Ç–≤–µ—Ç –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –¥–ª–∏–Ω–µ (—Å–ª–æ–≤: {word_count}): {answer}")
                return None
                
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —è–∑—ã–∫–∞
            if model_config.language == "ru":
                has_cyrillic = any(1040 <= ord(c) <= 1279 for c in answer)
                has_latin = any(c.isalpha() and ord(c) < 1024 for c in answer if c not in ' !?.,üòäüòâüòçüòòüíïüî•')
                if not has_cyrillic or has_latin:
                    logger.warning(f"–û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞: {answer}")
                    return None
            else:
                if any(1040 <= ord(c) <= 1279 for c in answer):
                    logger.warning(f"–û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä—É—Å—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞: {answer}")
                    return None
                    
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–ª–∏—Ä—Ç–æ–≤–æ–≥–æ —Å—Ç–∏–ª—è
            flirty_words = ["–º–∏–ª—ã–π", "–∫—Ä–∞—Å–∏–≤", "—à–∞–ª–∏—Ç—å", "—Ñ–ª–∏—Ä—Ç", "–ø—Ä–∏–≤–µ—Ç–∏–∫", "cutie", "naughty", "flirt", "hey", "gorgeous", "handsome"]
            if not any(word in answer.lower() for word in flirty_words):
                logger.warning(f"–û—Ç–≤–µ—Ç –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–ª–∏—Ä—Ç–æ–≤–æ–º—É —Å—Ç–∏–ª—é: {answer}")
                return None
                
            return answer
    except requests.ConnectionError as e:
        logger.warning(f"Connection error with Ollama: {e}")
        return None
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Ollama: {e}")
        return None

def parse_spin_syntax(text: str) -> str:
    logger.debug(f"Parsing spin syntax for text: {text}")
    spin_regex = r'{([^}]+)}'
    def replace_spin(match):
        options = [opt.strip() for opt in match.group(1).split('|')]
        return random.choice(options)
    parsed_text = re.sub(spin_regex, replace_spin, text)
    logger.debug(f"Parsed text: {parsed_text}")
    return parsed_text

async def generate_ai_response(message: str, model_config: ModelConfig, conversation_state: dict, model_name: str) -> str:
    logger.info(f"Generating response for message: '{message}', model: '{model_name}' (display: '{model_config.name}'), language: '{model_config.language}'")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç—Ä–∏–≥–≥–µ—Ä—ã
    message_lower = message.lower().strip()
    for trigger in model_config.triggers:
        if trigger.lower().strip() in message_lower:
            logger.info(f"Trigger '{trigger}' detected! Returning final message immediately.")
            return parse_spin_syntax(model_config.final_message)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π
    if conversation_state["message_count"] == model_config.message_count - 1:
        logger.info("Returning semi_message")
        return parse_spin_syntax(model_config.semi_message)
    
    if conversation_state["message_count"] >= model_config.message_count:
        logger.info("Returning final_message")
        return parse_spin_syntax(model_config.final_message)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—É—á–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
    trained_response = await get_trained_response(message, model_name)
    if trained_response:
        logger.info(f"Found trained response: '{trained_response}'")
        parsed_response = parse_spin_syntax(trained_response)
        logger.info(f"Parsed trained response: '{parsed_response}'")
        return parsed_response
    
    # –ü—Ä–æ–±—É–µ–º Ollama
    logger.warning(f"No trained response found, trying Ollama...")
    ollama_response = await get_ollama_response(message, model_config)
    if ollama_response:
        logger.info(f"Got Ollama response: '{ollama_response}'")
        return parse_spin_syntax(ollama_response)
    
    # –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
    logger.warning(f"Ollama unavailable, using default logic")
    if model_config.language == "ru":
        responses = {
            "greetings": ["–ü—Ä–∏–≤–µ—Ç", "–ü—Ä–∏–≤–µ—Ç–∏–∫ –∂", "–•–∞–π —è –¥", "–ü—Ä–∏–≤–µ—Ç –∂", "–ü—Ä–∏–≤–µ—Ç, —è –ñ"],
            "age_questions": [f"{model_config.age}, –∞ —Ç–µ–±–µ? üòâ", "{model_config.age}", "{model_config.age}üòç", f"–ú–Ω–µ {model_config.age}! üíï"],
            "location_questions": [f"–ò–∑ {model_config.city}! üòç", f"{model_config.city}, —Ç—ã –≥–¥–µ? üòâ", f"{model_config.country}! üíï", f"–ñ–∏–≤—É –≤ {model_config.city}! üòä"],
            "flirty": ["—Ö–º–º"],
            "default": ["—Ö–º"]
        }
    else:
        responses = {
            "greetings": ["Hey", "Hi", "Yo", "Hello", "Hi."],
            "age_questions": [f"{model_config.age}, you? üòâ"],
            "location_questions": [f"From {model_config.city}! üòç", f"{model_config.city}, you? üòâ", f"{model_config.country}! üíï", f"Live in {model_config.city}! üòä"],
            "flirty": ["hmm"],
            "default": ["hm"]
        }
    
    if any(word in message_lower for word in ["–ø—Ä–∏–≤–µ—Ç", "hi", "hey", "hello", "—Ö–∞–π"]):
        response = random.choice(responses["greetings"])
        logger.info(f"Generated greeting response: '{response}'")
    elif any(word in message_lower for word in ["—Å–∫ –ª–µ—Ç", "age", "—Å–∫–æ–ª—å–∫–æ –ª–µ—Ç", "how old", "–≤–æ–∑—Ä–∞—Å—Ç"]):
        response = random.choice(responses["age_questions"])
        logger.info(f"Generated age response: '{response}'")
    elif any(word in message_lower for word in ["–æ—Ç–∫—É–¥–∞", "from", "–≥–æ—Ä–æ–¥", "where", "city"]):
        response = random.choice(responses["location_questions"])
        logger.info(f"Generated location response: '{response}'")
    elif any(word in message_lower for word in ["—à–∞–ª–∏—Ç—å", "horny", "—Ö–æ—á—É", "want", "m or f", "naughty", "—Å–µ–∫—Å"]):
        response = random.choice(responses["flirty"])
        logger.info(f"Generated flirty response: '{response}'")
    elif "hiiii f18" in message_lower:
        response = "Hey cutie! üòâ" if model_config.language == "en" else "–ü—Ä–∏–≤–µ—Ç, –º–∏–ª–∞—è! üòâ"
        logger.info(f"Generated specific response for 'hiiii f18': '{response}'")
    else:
        response = random.choice(responses["default"])
        logger.info(f"Generated default response: '{response}'")
    
    if model_config.use_emoji and not any(emoji in response for emoji in ["üòò", "üòä", "üòâ", "üíï", "üî•", "üòç"]):
        emojis = ["üòò", "üòä", "üòâ", "üíï", "üî•", "üòç"]
        response += f" {random.choice(emojis)}"
    
    return parse_spin_syntax(response)

async def get_trained_response(message: str, model: str) -> Optional[str]:
    message_lower = message.lower().strip()
    logger.debug(f"Checking trained response for message: '{message_lower}', model: '{model}'")
    
    # –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    escaped_message = re.escape(message_lower)
    exact_match = await db.trained_responses.find_one({
        "question": escaped_message,
        "model": model
    }, sort=[("priority", -1)])
    if exact_match:
        logger.info(f"Found exact match for '{message_lower}' with priority {exact_match.get('priority', 1)}")
        return exact_match["answer"]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    words = message_lower.split()
    for word in words:
        if len(word) > 3:
            escaped_word = re.escape(word)
            logger.debug(f"Checking keyword: '{escaped_word}'")
            try:
                responses = await db.trained_responses.find({
                    "question": {"$regex": escaped_word, "$options": "i"},
                    "model": model
                }).sort([("priority", -1)]).limit(5).to_list(length=None)
                
                if responses:
                    best_response = responses[0]
                    logger.info(f"Found keyword match for '{message_lower}' using word '{word}' with priority {best_response.get('priority', 1)}")
                    return best_response["answer"]
            except Exception as e:
                logger.error(f"Regex error for word '{word}': {e}")
                continue
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    try:
        partial_matches = await db.trained_responses.find({
            "question": {"$regex": escaped_message, "$options": "i"},
            "model": model
        }).sort([("priority", -1)]).limit(3).to_list(length=None)
        
        if partial_matches:
            best_match = partial_matches[0]
            logger.info(f"Found partial match for '{message_lower}' with priority {best_match.get('priority', 1)}")
            return best_match["answer"]
    except Exception as e:
        logger.error(f"Regex error for message '{message_lower}': {e}")
    
    logger.info(f"No trained response found for '{message_lower}'")
    return None

# API Endpoints
@api_router.get("/")
async def root():
    logger.debug("Received request to /api/")
    return {"message": "AI Sexter Bot API v2.0"}

@api_router.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    logger.debug(f"Received chat request: {request.model_dump()}")
    try:
        model_config = await load_model(request.model)
        conversation_state = get_conversation_state(request.user_id, request.model)
        conversation_state["message_count"] += 1
        conversation_state["last_activity"] = datetime.now(dt.UTC)
        conversation_state["messages"].append({
            "user_message": request.message,
            "timestamp": datetime.now(dt.UTC)
        })
        
        ai_response = await generate_ai_response(request.message, model_config, conversation_state, request.model)
        
        await db.bot_activities.insert_one({
            "model": request.model,
            "action": "chat_response",
            "user_message": request.message,
            "ai_response": ai_response,
            "timestamp": datetime.now(dt.UTC)
        })
        
        trigger_detected = ai_response == parse_spin_syntax(model_config.final_message)
        is_semi = conversation_state["message_count"] == model_config.message_count - 1 and not trigger_detected
        is_last = conversation_state["message_count"] >= model_config.message_count or trigger_detected
        
        await db.conversations.insert_one({
            "user_id": request.user_id,
            "model": request.model,
            "user_message": request.message,
            "ai_response": ai_response,
            "message_number": conversation_state["message_count"],
            "is_semi": is_semi,
            "is_last": is_last,
            "emotion": detect_emotion(request.message),
            "timestamp": datetime.now(dt.UTC)
        })
        
        return ChatResponse(
            response=ai_response,
            message_number=conversation_state["message_count"],
            is_semi=is_semi,
            is_last=is_last,
            emotion=detect_emotion(request.message),
            model_used=request.model
        )
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ chat: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/test")
async def test_chat(request: TestRequest):
    logger.debug(f"Received test request: {request.model_dump()}")
    try:
        model_config = await load_model(request.model)
        temp_state = {"message_count": 1, "messages": []}
        response = await generate_ai_response(request.message, model_config, temp_state, request.model)
        
        return {
            "response": response,
            "model": request.model,
            "emotion": detect_emotion(request.message)
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ test: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/rate")
async def rate_response(request: RatingRequest):
    logger.debug(f"Received rate request: {request.model_dump()}")
    try:
        await db.ratings.insert_one({
            "user_id": request.user_id,
            "model": request.model,
            "message": request.message,
            "response": request.response,
            "rating": request.rating,
            "timestamp": datetime.now(dt.UTC)
        })
        
        await db.statistics.update_one(
            {"type": "ratings", "model": request.model},
            {
                "$inc": {"total_ratings": 1, "total_score": request.rating},
                "$set": {"updated_at": datetime.now(dt.UTC)}
            },
            upsert=True
        )
        
        if request.rating >= 8:
            await db.trained_responses.update_one(
                {"question": request.message.lower().strip(), "model": request.model},
                {
                    "$set": {
                        "answer": request.response,
                        "priority": request.rating,
                        "auto_trained": True,
                        "updated_at": datetime.now(dt.UTC)
                    }
                },
                upsert=True
            )
            logger.info(f"Auto-trained response for '{request.message}' with rating {request.rating}")
        
        return {"message": "–†–µ–π—Ç–∏–Ω–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω" + (" –∏ –æ—Ç–≤–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ–±—É—á–µ–Ω–∏–µ" if request.rating >= 8 else "")}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ rate: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/train")
async def train_model(request: TrainingRequest):
    logger.debug(f"Received train request: {request.model_dump()}")
    try:
        await db.trained_responses.update_one(
            {"question": request.question.lower().strip(), "model": request.model},
            {
                "$set": {
                    "answer": request.answer,
                    "priority": request.priority,
                    "updated_at": datetime.now(dt.UTC)
                }
            },
            upsert=True
        )
        
        return {"message": "–û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã"}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ train: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/train-file")
async def train_from_file(model: str, file: UploadFile = File(...)):
    try:
        content = await file.read()
        content = content.decode('utf-8')
        
        lines = content.split('\n')
        processed = 0
        
        for line in lines:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
                
            separators = [' - ', ' | ', '\t']
            question, answer = None, None
            
            for sep in separators:
                if sep in line:
                    parts = line.split(sep, 1)
                    if len(parts) == 2:
                        question = parts[0].strip()
                        answer = parts[1].strip()
                        break
            
            if question and answer:
                await db.trained_responses.update_one(
                    {"question": question.lower(), "model": model},
                    {
                        "$set": {
                            "answer": answer,
                            "priority": 5,
                            "file_trained": True,
                            "updated_at": datetime.now(dt.UTC)
                        }
                    },
                    upsert=True
                )
                processed += 1
        
        return {"message": f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed} –∑–∞–ø–∏—Å–µ–π –∏–∑ —Ñ–∞–π–ª–∞"}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/models")
async def get_models():
    logger.debug("Received request to /api/models")
    try:
        models = []
        for model_file in MODELS_DIR.glob("*.json"):
            model_name = model_file.stem
            try:
                model_config = await load_model(model_name)
                models.append({
                    "name": model_name,
                    "display_name": model_config.name,
                    "language": model_config.language,
                    "country": model_config.country
                })
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
        
        return {"models": models}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ get_models: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/model/{model_name}")
async def get_model(model_name: str):
    logger.debug(f"Received request to /api/model/{model_name}")
    try:
        model_config = await load_model(model_name)
        return model_config.model_dump()
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ get_model: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/model/{model_name}")
async def save_model_config(model_name: str, config: ModelConfig):
    logger.debug(f"Received request to save model: {model_name}")
    try:
        await save_model(model_name, config)
        return {"message": f"–ú–æ–¥–µ–ª—å {model_name} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞"}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ save_model_config: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/statistics")
async def get_statistics():
    logger.debug("Received request to /api/statistics")
    try:
        total_conversations = await db.conversations.count_documents({})
        total_users = len(await db.conversations.distinct("user_id"))
        
        models_stats = await db.conversations.aggregate([
            {"$group": {
                "_id": "$model",
                "conversations": {"$sum": 1},
                "avg_rating": {"$avg": "$rating"}
            }}
        ]).to_list(length=None)
        
        top_responses = await db.conversations.aggregate([
            {"$group": {
                "_id": "$ai_response",
                "count": {"$sum": 1}
            }},
            {"$sort": {"count": -1}},
            {"$limit": 10}
        ]).to_list(length=None)
        
        top_questions = await db.conversations.aggregate([
            {"$group": {
                "_id": "$user_message",
                "count": {"$sum": 1}
            }},
            {"$sort": {"count": -1}},
            {"$limit": 10}
        ]).to_list(length=None)
        
        ratings_stats = await db.ratings.aggregate([
            {"$group": {
                "_id": "$model",
                "avg_rating": {"$avg": "$rating"},
                "total_ratings": {"$sum": 1}
            }}
        ]).to_list(length=None)
        
        problem_questions = await db.ratings.find(
            {"rating": {"$lte": 3}},
            {"message": 1, "response": 1, "rating": 1, "model": 1}
        ).limit(10).to_list(length=None)
        
        return {
            "total_conversations": total_conversations,
            "total_users": total_users,
            "models_stats": models_stats,
            "top_responses": top_responses,
            "top_questions": top_questions,
            "ratings_stats": ratings_stats,
            "problem_questions": problem_questions,
            "system_status": {
                "database_connected": True,
                "models_loaded": len(loaded_models),
                "active_conversations": len(conversation_states)
            }
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ statistics: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/statistics/{model_name}")
async def get_model_statistics(model_name: str):
    logger.debug(f"Received request to /api/statistics/{model_name}")
    try:
        total_conversations = await db.conversations.count_documents({"model": model_name})
        total_users = len(await db.conversations.distinct("user_id", {"model": model_name}))
        
        top_responses = await db.conversations.aggregate([
            {"$match": {"model": model_name}},
            {"$group": {
                "_id": "$ai_response",
                "count": {"$sum": 1}
            }},
            {"$sort": {"count": -1}},
            {"$limit": 10}
        ]).to_list(length=None)
        
        top_questions = await db.conversations.aggregate([
            {"$match": {"model": model_name}},
            {"$group": {
                "_id": "$user_message",
                "count": {"$sum": 1}
            }},
            {"$sort": {"count": -1}},
            {"$limit": 10}
        ]).to_list(length=None)
        
        avg_rating = await db.ratings.aggregate([
            {"$match": {"model": model_name}},
            {"$group": {
                "_id": None,
                "avg_rating": {"$avg": "$rating"},
                "total_ratings": {"$sum": 1}
            }}
        ]).to_list(length=None)
        
        rating_info = avg_rating[0] if avg_rating else {"avg_rating": 0, "total_ratings": 0}
        
        problem_questions = await db.ratings.find(
            {"model": model_name, "rating": {"$lte": 3}},
            {"message": 1, "response": 1, "rating": 1}
        ).limit(10).to_list(length=None)
        
        trained_count = await db.trained_responses.count_documents({"model": model_name})
        
        return {
            "model": model_name,
            "total_conversations": total_conversations,
            "total_users": total_users,
            "avg_rating": rating_info["avg_rating"],
            "total_ratings": rating_info["total_ratings"],
            "trained_responses": trained_count,
            "top_responses": top_responses,
            "top_questions": top_questions,
            "problem_questions": problem_questions
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ model statistics: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.delete("/statistics/{model_name}")
async def clear_model_statistics(model_name: str):
    logger.debug(f"Received request to clear statistics for model: {model_name}")
    try:
        conversations_deleted = await db.conversations.delete_many({"model": model_name})
        ratings_deleted = await db.ratings.delete_many({"model": model_name})
        activities_deleted = await db.bot_activities.delete_many({"model": model_name})
        stats_deleted = await db.statistics.delete_many({"model": model_name})
        
        return {
            "message": f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏ {model_name} –æ—á–∏—â–µ–Ω–∞",
            "deleted": {
                "conversations": conversations_deleted.deleted_count,
                "ratings": ratings_deleted.deleted_count,
                "activities": activities_deleted.deleted_count,
                "statistics": stats_deleted.deleted_count
            },
            "preserved": {
                "trained_responses": "—Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã"
            }
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/settings")
async def get_settings():
    logger.debug("Received request to /api/settings")
    try:
        settings = await db.user_settings.find_one({"type": "global_settings"})
        if settings:
            settings.pop("_id", None)
            settings.pop("type", None)
            return settings
        else:
            return {"default_model": "", "auto_save": True}
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ get_settings: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/settings")
async def save_settings(settings: dict):
    logger.debug(f"Received request to save settings: {settings}")
    try:
        await db.user_settings.update_one(
            {"type": "global_settings"},
            {
                "$set": {
                    **settings,
                    "updated_at": datetime.now(dt.UTC)
                }
            },
            upsert=True
        )
        
        return {"message": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã", "status": "success"}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ save_settings: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/health")
async def health_check():
    logger.debug("Received request to /api/health")
    try:
        await db.command("ping")
        db_status = True
    except:
        db_status = False
    
    return {
        "status": "healthy" if db_status else "unhealthy",
        "database": db_status,
        "models_loaded": len(loaded_models),
        "active_conversations": len(conversation_states),
        "timestamp": datetime.now(dt.UTC)
    }

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ api_router
app.include_router(api_router)



if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)