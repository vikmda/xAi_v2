from fastapi import FastAPI, HTTPException, APIRouter
from fastapi.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
from pydantic import BaseModel, Field
from typing import List, Optional
from datetime import datetime
import datetime as dt
import os
import json
import requests
import logging
from pathlib import Path
import aiofiles
import asyncio

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
from dotenv import load_dotenv
load_dotenv()

# MongoDB –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
MONGO_URL = os.getenv("MONGO_URL", "mongodb://localhost:27017")
DB_NAME = os.getenv("DB_NAME", "ai_sexter_bot")

client = AsyncIOMotorClient(MONGO_URL)
db = client[DB_NAME]

# FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(title="AI Sexter Bot API", version="2.0.0")
api_router = APIRouter(prefix="/api")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class ChatRequest(BaseModel):
    model: str = Field(..., description="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞")
    user_id: str = Field(..., description="ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    message: str = Field(..., description="–°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")

class ChatResponse(BaseModel):
    response: str
    message_number: int
    is_semi: bool
    is_last: bool
    emotion: Optional[str] = None
    model_used: str

class RatingRequest(BaseModel):
    user_id: str
    message: str
    response: str
    rating: int = Field(..., ge=1, le=10)
    model: str

class TrainingRequest(BaseModel):
    question: str
    answer: str
    model: str
    priority: int = Field(default=1, ge=1, le=10)

class ModelConfig(BaseModel):
    name: str
    age: int
    country: str
    city: str
    language: str
    interests: List[str]
    mood: str
    message_count: int
    semi_message: str
    final_message: str
    learning_enabled: bool
    response_length: int
    use_emoji: bool
    personality_traits: List[str] = []

class TestRequest(BaseModel):
    message: str
    model: str

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
MODELS_DIR = Path(__file__).parent / "models"
loaded_models = {}
conversation_states = {}

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π
MODELS_DIR.mkdir(exist_ok=True)
logger.info(f"MODELS_DIR set to: {MODELS_DIR}")

# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏
async def load_model(model_name: str) -> ModelConfig:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ JSON —Ñ–∞–π–ª–∞"""
    logger.debug(f"Loading model: {model_name}")
    if model_name in loaded_models:
        logger.debug(f"Model {model_name} already loaded from cache")
        return loaded_models[model_name]
    
    model_path = MODELS_DIR / f"{model_name}.json"
    logger.debug(f"Checking model file at: {model_path}")
    if not model_path.exists():
        logger.error(f"Model file {model_path} does not exist")
        raise HTTPException(status_code=404, detail=f"–ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    async with aiofiles.open(model_path, 'r', encoding='utf-8') as f:
        content = await f.read()
        model_data = json.loads(content)
        model_config = ModelConfig(**model_data)
        loaded_models[model_name] = model_config
        logger.info(f"Model {model_name} loaded successfully")
        return model_config

async def save_model(model_name: str, config: ModelConfig):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ JSON —Ñ–∞–π–ª"""
    logger.debug(f"Saving model: {model_name}")
    model_path = MODELS_DIR / f"{model_name}.json"
    async with aiofiles.open(model_path, 'w', encoding='utf-8') as f:
        await f.write(json.dumps(config.model_dump(), ensure_ascii=False, indent=2))
    loaded_models[model_name] = config
    logger.info(f"Model {model_name} saved successfully")

def get_conversation_state(user_id: str, model: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞"""
    key = f"{user_id}_{model}"
    if key not in conversation_states:
        conversation_states[key] = {
            "message_count": 0,
            "messages": [],
            "last_activity": datetime.now(dt.UTC)
        }
    return conversation_states[key]

def detect_emotion(message: str) -> str:
    """–ü—Ä–æ—Å—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç–º–æ—Ü–∏–∏"""
    message_lower = message.lower()
    if any(word in message_lower for word in ["–∫—Ä–∞—Å–∏–≤", "—Å–µ–∫—Å—É–∞–ª—å–Ω", "–ø—Ä–∏–≤–ª–µ–∫–∞—Ç", "beautiful", "gorgeous", "hot"]):
        return "flirty"
    elif any(word in message_lower for word in ["–ª—é–±–ª—é", "–æ–±–æ–∂–∞—é", "–¥–æ—Ä–æ–≥", "love", "adore"]):
        return "romantic"
    elif any(word in message_lower for word in ["—Ö–æ—á—É", "–∂–µ–ª–∞—é", "—Å—Ç—Ä–∞—Å—Ç—å", "want", "desire", "horny"]):
        return "seductive"
    elif any(word in message_lower for word in ["–∏–≥—Ä–∞—Ç—å", "—à–∞–ª–∏—Ç—å", "–≤–µ—Å–µ–ª—å–µ", "play", "naughty"]):
        return "playful"
    else:
        return "neutral"

async def adapt_model_to_platform(model_config: ModelConfig, platform_settings: dict) -> ModelConfig:
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –ø–æ–¥ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã"""
    if not platform_settings.get("auto_adapt", False):
        return model_config
    
    age_range = platform_settings.get("age_range", {"min": 18, "max": 35})
    model_config.age = min(max(model_config.age, age_range["min"]), age_range["max"])
    
    if platform_settings.get("default_country"):
        model_config.country = platform_settings["default_country"]
    if platform_settings.get("default_language"):
        model_config.language = platform_settings["default_language"]
    
    msg_limits = platform_settings.get("message_limits", {"min": 3, "max": 8})
    model_config.message_count = min(max(model_config.message_count, msg_limits["min"]), msg_limits["max"])
    
    response_style = platform_settings.get("response_style", "flirty")
    if response_style not in model_config.personality_traits:
        model_config.personality_traits.append(response_style)
    
    model_config.use_emoji = platform_settings.get("emoji_usage", True)
    
    return model_config

async def get_ollama_response(message: str, model_config: ModelConfig) -> Optional[str]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ Ollama –ò–ò"""
    try:
        personality = ", ".join(model_config.personality_traits)
        interests = ", ".join(model_config.interests)
        if model_config.language == "ru":
            prompt = (
                f"–¢—ã {model_config.name}, {model_config.age}-–ª–µ—Ç–Ω—è—è –¥–µ–≤—É—à–∫–∞ –∏–∑ –≥–æ—Ä–æ–¥–∞ {model_config.city}, {model_config.country}. "
                f"–¢–≤–æ–∏ –∏–Ω—Ç–µ—Ä–µ—Å—ã: {interests}. –¢–≤–æ—ë –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {model_config.mood}. –•–∞—Ä–∞–∫—Ç–µ—Ä: {personality}. "
                f"–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, —Å—Ç—Ä–æ–≥–æ 2-4 —Å–ª–æ–≤–∞, –≤ —Ñ–ª–∏—Ä—Ç—É—é—â–µ–º —Å—Ç–∏–ª–µ. "
                f"–ó–∞–ø—Ä–µ—â–µ–Ω—ã –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞, –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –∏ –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã. "
                f"{'–ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –≤ –∫–æ–Ω—Ü–µ.' if model_config.use_emoji else '–ë–µ–∑ —ç–º–æ–¥–∑–∏.'} "
                f"–ü—Ä–∏–º–µ—Ä—ã:\n"
                f"- –í–æ–ø—Ä–æ—Å: –ü—Ä–∏–≤–µ—Ç\n  –û—Ç–≤–µ—Ç: –ü—Ä–∏–≤–µ—Ç–∏–∫! {'üòä' if model_config.use_emoji else ''}\n"
                f"- –í–æ–ø—Ä–æ—Å: –°–∫ –ª–µ—Ç?\n  –û—Ç–≤–µ—Ç: {model_config.age}, –∞ —Ç–µ–±–µ? {'üòâ' if model_config.use_emoji else ''}\n"
                f"- –í–æ–ø—Ä–æ—Å: –û—Ç–∫—É–¥–∞ —Ç—ã?\n  –û—Ç–≤–µ—Ç: –ò–∑ {model_config.city}! {'üòç' if model_config.use_emoji else ''}\n"
                f"- –í–æ–ø—Ä–æ—Å: –ë—É–¥–µ–º —à–∞–ª–∏—Ç—å?\n  –û—Ç–≤–µ—Ç: –û–≥–æ, —Å–º–µ–ª–æ! {'üòè' if model_config.use_emoji else ''}\n"
                f"–°–æ–æ–±—â–µ–Ω–∏–µ: {message}"
            )
            forbidden_phrases = ["provide information", "–Ω–µ –º–æ–≥—É", "illegal", "harmful", "sorry", "cannot"]
        else:
            prompt = (
                f"You are {model_config.name}, a {model_config.age}-year-old girl from {model_config.city}, {model_config.country}. "
                f"Your interests: {interests}. Your mood: {model_config.mood}. Personality: {personality}. "
                f"Reply only in English, strictly 2-4 words, in a flirty style. "
                f"No Russian words, warnings, or long responses allowed. "
                f"{'Add an emoji at the end.' if model_config.use_emoji else 'No emojis.'} "
                f"Examples:\n"
                f"- Question: Hey\n  Answer: Hey cutie! {'üòä' if model_config.use_emoji else ''}\n"
                f"- Question: Age?\n  Answer: {model_config.age}, you? {'üòâ' if model_config.use_emoji else ''}\n"
                f"- Question: From?\n  Answer: {model_config.city}! {'üòç' if model_config.use_emoji else ''}\n"
                f"- Question: Horny?\n  Answer: Oh, naughty! {'üòè' if model_config.use_emoji else ''}\n"
                f"Message: {message}"
            )
            forbidden_phrases = ["provide information", "I cannot", "illegal", "harmful", "sorry", "–Ω–µ –º–æ–≥—É"]

        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": "llama3.2:1b",
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.5,
                    "top_p": 0.8,
                    "max_tokens": 15
                }
            },
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            answer = result.get("response", "").strip()
            logger.debug(f"Ollama response for {model_config.language}: {answer}")
            if any(phrase in answer.lower() for phrase in forbidden_phrases):
                logger.warning(f"–ù–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç Ollama: {answer}")
                return None
            if len(answer.split()) > 4:
                logger.warning(f"–û—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π: {answer}")
                return None
            if model_config.language == "ru" and any(ord(c) < 1024 and c not in ' !?.,' for c in answer):
                logger.warning(f"–û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ-—Ä—É—Å—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã: {answer}")
                return None
            if model_config.language == "en" and any(1024 <= ord(c) <= 1279 for c in answer):
                logger.warning(f"–û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä—É—Å—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã: {answer}")
                return None
            return answer
    except Exception as e:
        logger.warning(f"Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    
    return None

async def generate_ai_response(message: str, model_config: ModelConfig, conversation_state: dict, model_name: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ò–ò"""
    logger.info(f"Generating response for message: '{message}', model: '{model_name}' (display: '{model_config.name}')")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∏–≥ –ª–∏ –¥–∏–∞–ª–æ–≥ –ø—Ä–µ–¥–ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    if conversation_state["message_count"] == model_config.message_count - 1:
        logger.info("Returning semi_message")
        return model_config.semi_message
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∏–≥ –ª–∏ –¥–∏–∞–ª–æ–≥ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    if conversation_state["message_count"] >= model_config.message_count:
        logger.info("Returning final_message")
        return model_config.final_message
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—É—á–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
    logger.info(f"Searching for trained response with model name: '{model_name}'")
    trained_response = await get_trained_response(message, model_name)
    if trained_response:
        logger.info(f"Found trained response: '{trained_response}'")
        return trained_response
    else:
        logger.warning(f"No trained response found, trying Ollama...")
    
    # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç Ollama
    ollama_response = await get_ollama_response(message, model_config)
    if ollama_response:
        logger.info(f"Got Ollama response: '{ollama_response}'")
        return ollama_response
    else:
        logger.warning(f"Ollama unavailable, using default logic")
    
    # –ë–∞–∑–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞
    responses = {
        "ru": {
            "greetings": ["–ü—Ä–∏–≤–µ—Ç, –∫—Ä–∞—Å–∞–≤—á–∏–∫!", "–ü—Ä–∏–≤–µ—Ç–∏–∫!", "–•–∞–π, –∫–∞–∫ –¥–µ–ª–∞?"],
            "age_questions": [f"{model_config.age}, –∞ —Ç–µ–±–µ?", "–Æ–Ω–∞—è, –∞ —Ç—ã?", "–í–æ–∑—Ä–∞—Å—Ç ‚Äî —Å–µ–∫—Ä–µ—Ç!"],
            "location_questions": [f"–ò–∑ {model_config.city}!", f"{model_config.city}, —Ç—ã –≥–¥–µ?", f"{model_config.country}!"],
            "flirty": ["–û–≥–æ, —Å–º–µ–ª–æ!", "–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ, –ø—Ä–æ–¥–æ–ª–∂–∞–π!", "–¢—ã –∏–Ω—Ç—Ä–∏–≥—É–µ—à—å!"],
            "default": ["–ö—Ä—É—Ç–æ!", "–°–µ—Ä—å—ë–∑–Ω–æ?", "–†–∞—Å—Å–∫–∞–∂–∏ –µ—â—ë!"]
        },
        "en": {
            "greetings": ["Hey handsome!", "Hi there!", "Yo, what's up?"],
            "age_questions": [f"{model_config.age}, you?", "Young, you?", "Age's a secret!"],
            "location_questions": [f"From {model_config.city}!", f"{model_config.city}, you?", f"{model_config.country}!"],
            "flirty": ["Oh, naughty!", "Keep talking!", "You're intriguing!"],
            "default": ["Cool!", "Really?", "Tell me more!"]
        }
    }
    
    lang_responses = responses.get(model_config.language, responses["ru"])
    
    message_lower = message.lower()
    if any(word in message_lower for word in ["–ø—Ä–∏–≤–µ—Ç", "hi", "hey", "hello"]):
        import random
        response = random.choice(lang_responses["greetings"])
        logger.info(f"Generated greeting response: '{response}'")
    elif any(word in message_lower for word in ["—Å–∫ –ª–µ—Ç", "age", "—Å–∫–æ–ª—å–∫–æ –ª–µ—Ç", "how old"]):
        import random
        response = random.choice(lang_responses["age_questions"])
        logger.info(f"Generated age response: '{response}'")
    elif any(word in message_lower for word in ["–æ—Ç–∫—É–¥–∞", "from", "–≥–æ—Ä–æ–¥", "where"]):
        import random
        response = random.choice(lang_responses["location_questions"])
        logger.info(f"Generated location response: '{response}'")
    elif any(word in message_lower for word in ["—à–∞–ª–∏—Ç—å", "horny", "—Ö–æ—á—É", "want", "m or f", "naughty"]):
        import random
        response = random.choice(lang_responses["flirty"])
        logger.info(f"Generated flirty response: '{response}'")
    else:
        import random
        response = random.choice(lang_responses["default"])
        logger.info(f"Generated default response: '{response}'")
    
    if model_config.use_emoji and not any(emoji in response for emoji in ["üòò", "üòä", "üòâ", "üíï", "üî•", "üòç"]):
        emojis = ["üòò", "üòä", "üòâ", "üíï", "üî•", "üòç"]
        import random
        response += f" {random.choice(emojis)}"
    
    return response

async def get_trained_response(message: str, model: str) -> Optional[str]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–µ–π"""
    message_lower = message.lower().strip()
    logger.debug(f"Checking trained response for message: '{message}', model: '{model}'")
    
    exact_match = await db.trained_responses.find_one({
        "question": message_lower,
        "model": model
    }, sort=[("priority", -1)])
    if exact_match:
        logger.info(f"Found exact match for '{message}' with priority {exact_match.get('priority', 1)}")
        return exact_match["answer"]
    
    words = message_lower.split()
    for word in words:
        if len(word) > 3:
            responses = await db.trained_responses.find({
                "question": {"$regex": word, "$options": "i"},
                "model": model
            }).sort([("priority", -1)]).limit(5).to_list(length=None)
            
            if responses:
                best_response = responses[0]
                logger.info(f"Found keyword match for '{message}' using word '{word}' with priority {best_response.get('priority', 1)}")
                return best_response["answer"]
    
    partial_matches = await db.trained_responses.find({
        "question": {"$regex": message_lower, "$options": "i"},
        "model": model
    }).sort([("priority", -1)]).limit(3).to_list(length=None)
    
    if partial_matches:
        best_match = partial_matches[0]
        logger.info(f"Found partial match for '{message}' with priority {best_match.get('priority', 1)}")
        return best_match["answer"]
    
    logger.info(f"No trained response found for '{message}'")
    return None

# API Endpoints
@api_router.get("/")
async def root():
    logger.debug("Received request to /api/")
    return {"message": "AI Sexter Bot API v2.0"}

@api_router.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """–û—Å–Ω–æ–≤–Ω–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è —á–∞—Ç–∞"""
    logger.debug(f"Received chat request: {request.model_dump()}")
    try:
        model_config = await load_model(request.model)
        platform_settings = await get_platform_settings()
        model_config = await adapt_model_to_platform(model_config, platform_settings)
        
        conversation_state = get_conversation_state(request.user_id, request.model)
        conversation_state["message_count"] += 1
        conversation_state["last_activity"] = datetime.now(dt.UTC)
        conversation_state["messages"].append({
            "user_message": request.message,
            "timestamp": datetime.now(dt.UTC)
        })
        
        ai_response = await generate_ai_response(request.message, model_config, conversation_state, request.model)
        
        is_semi = conversation_state["message_count"] == model_config.message_count - 1
        is_last = conversation_state["message_count"] >= model_config.message_count
        
        await db.conversations.insert_one({
            "user_id": request.user_id,
            "model": request.model,
            "user_message": request.message,
            "ai_response": ai_response,
            "message_number": conversation_state["message_count"],
            "is_semi": is_semi,
            "is_last": is_last,
            "emotion": detect_emotion(request.message),
            "platform_adapted": True,
            "timestamp": datetime.now(dt.UTC)
        })
        
        return ChatResponse(
            response=ai_response,
            message_number=conversation_state["message_count"],
            is_semi=is_semi,
            is_last=is_last,
            emotion=detect_emotion(request.message),
            model_used=request.model
        )
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ chat: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/test")
async def test_chat(request: TestRequest):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    logger.debug(f"Received test request: {request.model_dump()}")
    try:
        model_config = await load_model(request.model)
        temp_state = {"message_count": 1, "messages": []}
        response = await generate_ai_response(request.message, model_config, temp_state, request.model)
        
        return {
            "response": response,
            "model": request.model,
            "emotion": detect_emotion(request.message)
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ test: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/rate")
async def rate_response(request: RatingRequest):
    """–û—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–±—É—á–µ–Ω–∏–µ–º –ø—Ä–∏ –≤—ã—Å–æ–∫–∏—Ö –æ—Ü–µ–Ω–∫–∞—Ö"""
    logger.debug(f"Received rate request: {request.model_dump()}")
    try:
        await db.ratings.insert_one({
            "user_id": request.user_id,
            "model": request.model,
            "message": request.message,
            "response": request.response,
            "rating": request.rating,
            "timestamp": datetime.now(dt.UTC)
        })
        
        await db.statistics.update_one(
            {"type": "ratings", "model": request.model},
            {
                "$inc": {"total_ratings": 1, "total_score": request.rating},
                "$set": {"updated_at": datetime.now(dt.UTC)}
            },
            upsert=True
        )
        
        if request.rating >= 8:
            await db.trained_responses.update_one(
                {"question": request.message.lower().strip(), "model": request.model},
                {
                    "$set": {
                        "answer": request.response,
                        "priority": request.rating,
                        "auto_trained": True,
                        "updated_at": datetime.now(dt.UTC)
                    }
                },
                upsert=True
            )
            logger.info(f"Auto-trained response for '{request.message}' with rating {request.rating}")
        
        return {"message": "–†–µ–π—Ç–∏–Ω–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω" + (" –∏ –æ—Ç–≤–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ–±—É—á–µ–Ω–∏–µ" if request.rating >= 8 else "")}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ rate: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/train")
async def train_model(request: TrainingRequest):
    """–†—É—á–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    logger.debug(f"Received train request: {request.model_dump()}")
    try:
        await db.trained_responses.update_one(
            {"question": request.question.lower().strip(), "model": request.model},
            {
                "$set": {
                    "answer": request.answer,
                    "priority": request.priority,
                    "updated_at": datetime.now(dt.UTC)
                }
            },
            upsert=True
        )
        
        return {"message": "–û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã"}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ train: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/models")
async def get_models():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    logger.debug("Received request to /api/models")
    try:
        models = []
        for model_file in MODELS_DIR.glob("*.json"):
            model_name = model_file.stem
            try:
                model_config = await load_model(model_name)
                models.append({
                    "name": model_name,
                    "display_name": model_config.name,
                    "language": model_config.language,
                    "country": model_config.country
                })
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
        
        return {"models": models}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ get_models: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/model/{model_name}")
async def get_model(model_name: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏"""
    logger.debug(f"Received request to /api/model/{model_name}")
    try:
        model_config = await load_model(model_name)
        return model_config.model_dump()
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ get_model: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/model/{model_name}")
async def save_model_config(model_name: str, config: ModelConfig):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏"""
    logger.debug(f"Received request to save model: {model_name}")
    try:
        await save_model(model_name, config)
        return {"message": f"–ú–æ–¥–µ–ª—å {model_name} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞"}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ save_model_config: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/statistics")
async def get_statistics():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã"""
    logger.debug("Received request to /api/statistics")
    try:
        total_conversations = await db.conversations.count_documents({})
        total_users = len(await db.conversations.distinct("user_id"))
        
        models_stats = await db.conversations.aggregate([
            {"$group": {
                "_id": "$model",
                "conversations": {"$sum": 1},
                "avg_rating": {"$avg": "$rating"}
            }}
        ]).to_list(length=None)
        
        top_responses = await db.conversations.aggregate([
            {"$group": {
                "_id": "$ai_response",
                "count": {"$sum": 1}
            }},
            {"$sort": {"count": -1}},
            {"$limit": 10}
        ]).to_list(length=None)
        
        top_questions = await db.conversations.aggregate([
            {"$group": {
                "_id": "$user_message",
                "count": {"$sum": 1}
            }},
            {"$sort": {"count": -1}},
            {"$limit": 10}
        ]).to_list(length=None)
        
        ratings_stats = await db.ratings.aggregate([
            {"$group": {
                "_id": "$model",
                "avg_rating": {"$avg": "$rating"},
                "total_ratings": {"$sum": 1}
            }}
        ]).to_list(length=None)
        
        problem_questions = await db.ratings.find(
            {"rating": {"$lte": 3}},
            {"message": 1, "response": 1, "rating": 1, "model": 1}
        ).limit(10).to_list(length=None)
        
        return {
            "total_conversations": total_conversations,
            "total_users": total_users,
            "models_stats": models_stats,
            "top_responses": top_responses,
            "top_questions": top_questions,
            "ratings_stats": ratings_stats,
            "problem_questions": problem_questions,
            "system_status": {
                "database_connected": True,
                "models_loaded": len(loaded_models),
                "active_conversations": len(conversation_states)
            }
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ statistics: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/settings")
async def get_settings():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫"""
    logger.debug("Received request to /api/settings")
    try:
        settings = await db.user_settings.find_one({"type": "global_settings"})
        if settings:
            settings.pop("_id", None)
            settings.pop("type", None)
            return settings
        else:
            return {"default_model": "", "auto_save": True}
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ get_settings: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/settings")
async def save_settings(settings: dict):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫"""
    logger.debug(f"Received request to save settings: {settings}")
    try:
        await db.user_settings.update_one(
            {"type": "global_settings"},
            {
                "$set": {
                    **settings,
                    "updated_at": datetime.now(dt.UTC)
                }
            },
            upsert=True
        )
        
        return {"message": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã", "status": "success"}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ save_settings: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/platform-settings")
async def get_platform_settings():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã"""
    logger.debug("Received request to /api/platform-settings")
    try:
        settings = await db.platform_settings.find_one({"type": "platform_config"})
        if settings:
            settings.pop("_id", None)
            settings.pop("type", None)
            return settings
        else:
            return {
                "default_country": "–†–æ—Å—Å–∏—è",
                "default_language": "ru",
                "age_range": {"min": 18, "max": 35},
                "response_style": "flirty",
                "platform_type": "dating",
                "auto_adapt": True,
                "message_limits": {"min": 3, "max": 8},
                "emoji_usage": True,
                "nsfw_level": "medium"
            }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ get_platform_settings: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/platform-settings")
async def save_platform_settings(settings: dict):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã"""
    logger.debug(f"Received request to save platform settings: {settings}")
    try:
        await db.platform_settings.update_one(
            {"type": "platform_config"},
            {
                "$set": {
                    **settings,
                    "updated_at": datetime.now(dt.UTC)
                }
            },
            upsert=True
        )
        
        return {"message": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã", "status": "success"}
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ save_platform_settings: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã"""
    logger.debug("Received request to /api/health")
    try:
        await db.command("ping")
        db_status = True
    except:
        db_status = False
    
    return {
        "status": "healthy" if db_status else "unhealthy",
        "database": db_status,
        "models_loaded": len(loaded_models),
        "active_conversations": len(conversation_states),
        "timestamp": datetime.now(dt.UTC)
    }

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ api_router –∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é
app.include_router(api_router)

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –æ—Ç–≤–µ—Ç–æ–≤ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
@app.on_event("startup")
async def create_default_models():
    """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –æ—Ç–≤–µ—Ç–æ–≤ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
    default_models = [
        {
            "name": "rus_girl_1",
            "config": ModelConfig(
                name="–ê–Ω–Ω–∞",
                age=23,
                country="–†–æ—Å—Å–∏—è",
                city="–ú–æ—Å–∫–≤–∞",
                language="ru",
                interests=["—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è", "–ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è", "–º—É–∑—ã–∫–∞"],
                mood="–∏–≥—Ä–∏–≤–æ–µ",
                message_count=5,
                semi_message="–•–æ—á–µ—à—å —É–≤–∏–¥–µ—Ç—å –º–æ–∏ —Ñ–æ—Ç–æ? üì∏",
                final_message="–ü–µ—Ä–µ—Ö–æ–¥–∏ –≤ –º–æ–π —Ç–µ–ª–µ–≥—Ä–∞–º @anna_model –¥–ª—è –±–æ–ª—å—à–µ–≥–æ üòò",
                learning_enabled=True,
                response_length=15,
                use_emoji=True,
                personality_traits=["flirty", "playful", "sweet"]
            )
        },
        {
            "name": "eng_girl_1",
            "config": ModelConfig(
                name="Emma",
                age=25,
                country="USA",
                city="New York",
                language="en",
                interests=["fitness", "travel", "photography"],
                mood="confident",
                message_count=5,
                semi_message="Want to see more of me? üíï",
                final_message="Check out my telegram @emma_model for exclusive content üòò",
                learning_enabled=True,
                response_length=12,
                use_emoji=True,
                personality_traits=["confident", "flirty", "adventurous"]
            )
        }
    ]
    
    for model_data in default_models:
        model_path = MODELS_DIR / f"{model_data['name']}.json"
        if not model_path.exists():
            await save_model(model_data['name'], model_data['config'])
            logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –¥–µ—Ñ–æ–ª—Ç–Ω–∞—è –º–æ–¥–µ–ª—å: {model_data['name']}")
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö –æ–±—É—á–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
    trained_responses = [
        {"question": "–ø—Ä–∏–≤–µ—Ç", "answer": "–ü—Ä–∏–≤–µ—Ç–∏–∫! üòä", "model": "rus_girl_1", "priority": 10},
        {"question": "—Å–∫ –ª–µ—Ç", "answer": "23, –∞ —Ç–µ–±–µ? üòâ", "model": "rus_girl_1", "priority": 9},
        {"question": "–æ—Ç–∫—É–¥–∞ —Ç—ã", "answer": "–ò–∑ –ú–æ—Å–∫–≤—ã! üòç", "model": "rus_girl_1", "priority": 9},
        {"question": "–±—É–¥–µ–º —à–∞–ª–∏—Ç—å", "answer": "–û–≥–æ, —Å–º–µ–ª–æ! üòè", "model": "rus_girl_1", "priority": 9},
        {"question": "hey", "answer": "Hey cutie! üíï", "model": "eng_girl_1", "priority": 10},
        {"question": "age?", "answer": "25, you? üòâ", "model": "eng_girl_1", "priority": 9},
        {"question": "from?", "answer": "New York! üòç", "model": "eng_girl_1", "priority": 9},
        {"question": "horny?", "answer": "Oh, naughty! üòè", "model": "eng_girl_1", "priority": 9}
    ]
    
    for response in trained_responses:
        await db.trained_responses.update_one(
            {"question": response["question"], "model": response["model"]},
            {
                "$set": {
                    "answer": response["answer"],
                    "priority": response["priority"],
                    "updated_at": datetime.now(dt.UTC)
                }
            },
            upsert=True
        )
        logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω –æ–±—É—á–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è '{response['question']}' –≤ –º–æ–¥–µ–ª—å '{response['model']}'")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)