from fastapi import FastAPI, HTTPException, APIRouter, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
from pydantic import BaseModel, Field
from typing import List, Optional
from datetime import datetime
import datetime as dt
import os
import json
import requests
import logging
from pathlib import Path
import aiofiles
import asyncio
import re
import random

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
from dotenv import load_dotenv
load_dotenv()

# MongoDB –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
MONGO_URL = os.getenv("MONGO_URL", "mongodb://localhost:27017")
DB_NAME = os.getenv("DB_NAME", "ai_sexter_bot")
client = AsyncIOMotorClient(MONGO_URL)
db = client[DB_NAME]

# FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(title="AI Sexter Bot API", version="2.0.0")
api_router = APIRouter(prefix="/api")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class ChatRequest(BaseModel):
    model: str = Field(..., description="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞")
    user_id: str = Field(..., description="ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    message: str = Field(..., description="–°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")

class ChatResponse(BaseModel):
    response: str
    message_number: int
    is_semi: bool
    is_last: bool
    emotion: Optional[str] = None
    model_used: str

class RatingRequest(BaseModel):
    user_id: str
    message: str
    response: str
    rating: int = Field(..., ge=1, le=10)
    model: str

class TrainingRequest(BaseModel):
    question: str
    answer: str
    model: str
    priority: int = Field(default=1, ge=1, le=10)

class ModelConfig(BaseModel):
    name: str
    age: int
    country: str
    city: str
    language: str
    interests: List[str]
    mood: str
    message_count: int
    semi_message: str
    final_message: str
    learning_enabled: bool
    response_length: int
    use_emoji: bool
    personality_traits: List[str] = []
    triggers: List[str] = []  # –¢—Ä–∏–≥–≥–µ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–≥–æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è

class TestRequest(BaseModel):
    message: str
    model: str

class StatsClearRequest(BaseModel):
    model: str

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
MODELS_DIR = Path(__file__).parent / "models"
loaded_models = {}
conversation_states = {}

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π
MODELS_DIR.mkdir(exist_ok=True)
logger.info(f"MODELS_DIR set to: {MODELS_DIR}")

# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏
async def load_model(model_name: str) -> ModelConfig:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ JSON —Ñ–∞–π–ª–∞"""
    logger.debug(f"Loading model: {model_name}")
    if model_name in loaded_models:
        logger.debug(f"Model {model_name} already loaded from cache")
        return loaded_models[model_name]
    
    model_path = MODELS_DIR / f"{model_name}.json"
    logger.debug(f"Checking model file at: {model_path}")
    if not model_path.exists():
        logger.error(f"Model file {model_path} does not exist")
        raise HTTPException(status_code=404, detail=f"–ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    async with aiofiles.open(model_path, 'r', encoding='utf-8') as f:
        content = await f.read()
        model_data = json.loads(content)
        model_config = ModelConfig(**model_data)
        loaded_models[model_name] = model_config
        logger.info(f"Model {model_name} loaded successfully from JSON")
        return model_config

async def save_model(model_name: str, config: ModelConfig):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ JSON —Ñ–∞–π–ª"""
    logger.debug(f"Saving model: {model_name}")
    model_path = MODELS_DIR / f"{model_name}.json"
    async with aiofiles.open(model_path, 'w', encoding='utf-8') as f:
        await f.write(json.dumps(config.model_dump(), ensure_ascii=False, indent=2))
    loaded_models[model_name] = config
    logger.info(f"Model {model_name} saved successfully")

def get_conversation_state(user_id: str, model: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞"""
    key = f"{user_id}_{model}"
    if key not in conversation_states:
        conversation_states[key] = {
            "message_count": 0,
            "messages": [],
            "last_activity": datetime.now(dt.UTC)
        }
    return conversation_states[key]

def detect_emotion(message: str) -> str:
    """–ü—Ä–æ—Å—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç–º–æ—Ü–∏–∏"""
    message_lower = message.lower()
    if any(word in message_lower for word in ["–∫—Ä–∞—Å–∏–≤", "—Å–µ–∫—Å—É–∞–ª—å–Ω", "–ø—Ä–∏–≤–ª–µ–∫–∞—Ç", "beautiful", "gorgeous", "hot"]):
        return "flirty"
    elif any(word in message_lower for word in ["–ª—é–±–ª—é", "–æ–±–æ–∂–∞—é", "–¥–æ—Ä–æ–≥", "love", "adore"]):
        return "romantic"
    elif any(word in message_lower for word in ["—Ö–æ—á—É", "–∂–µ–ª–∞—é", "—Å—Ç—Ä–∞—Å—Ç—å", "want", "desire", "horny"]):
        return "seductive"
    elif any(word in message_lower for word in ["–∏–≥—Ä–∞—Ç—å", "—à–∞–ª–∏—Ç—å", "–≤–µ—Å–µ–ª—å–µ", "play", "naughty"]):
        return "playful"
    else:
        return "neutral"

async def get_ollama_response(message: str, model_config: ModelConfig) -> Optional[str]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ Ollama –ò–ò —Å —Å—Ç—Ä–æ–≥–∏–º —Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ–º —è–∑—ã–∫—É –º–æ–¥–µ–ª–∏"""
    try:
        personality = ", ".join(model_config.personality_traits)
        interests = ", ".join(model_config.interests)
        
        # –°–¢–†–û–ì–û —Å–ª–µ–¥—É–µ–º —è–∑—ã–∫—É –º–æ–¥–µ–ª–∏ –∏–∑ JSON –Ω–∞—Å—Ç—Ä–æ–µ–∫
        if model_config.language == "ru":
            prompt = (
                f"–¢—ã {model_config.name}, {model_config.age}-–ª–µ—Ç–Ω—è—è –¥–µ–≤—É—à–∫–∞ –∏–∑ –≥–æ—Ä–æ–¥–∞ {model_config.city}, {model_config.country}. "
                f"–¢–≤–æ–∏ –∏–Ω—Ç–µ—Ä–µ—Å—ã: {interests}. –¢–≤–æ—ë –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {model_config.mood}. –•–∞—Ä–∞–∫—Ç–µ—Ä: {personality}. "
                f"–í–ê–ñ–ù–û: –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, —Å—Ç—Ä–æ–≥–æ 2-4 —Å–ª–æ–≤–∞, –≤ —Ñ–ª–∏—Ä—Ç—É—é—â–µ–º —Å—Ç–∏–ª–µ. "
                f"–ó–ê–ü–†–ï–©–ï–ù–´ –ª—é–±—ã–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞, –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –∏ –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã. "
                f"–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π —Ä—É—Å—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π –ª–∞—Ç–∏–Ω–∏—Ü—É. "
                f"{'–ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –≤ –∫–æ–Ω—Ü–µ.' if model_config.use_emoji else '–ë–µ–∑ —ç–º–æ–¥–∑–∏.'} "
                f"–°–æ–æ–±—â–µ–Ω–∏–µ: {message}"
            )
            forbidden_phrases = ["provide information", "–Ω–µ –º–æ–≥—É", "illegal", "harmful", "sorry", "cannot", "english"]
        else:  # English
            prompt = (
                f"You are {model_config.name}, a {model_config.age}-year-old girl from {model_config.city}, {model_config.country}. "
                f"Your interests: {interests}. Your mood: {model_config.mood}. Personality: {personality}. "
                f"IMPORTANT: Reply ONLY in English, strictly 2-4 words, in a flirty style. "
                f"FORBIDDEN: Russian words, warnings, or long responses. "
                f"MUST use only English characters and avoid Cyrillic. "
                f"{'Add an emoji at the end.' if model_config.use_emoji else 'No emojis.'} "
                f"Message: {message}"
            )
            forbidden_phrases = ["provide information", "I cannot", "illegal", "harmful", "sorry", "–Ω–µ –º–æ–≥—É", "russian"]
        
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": "llama3.2:1b",
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.5,
                    "top_p": 0.8,
                    "max_tokens": 15
                }
            },
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            answer = result.get("response", "").strip()
            logger.debug(f"Ollama response for {model_config.language}: {answer}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã
            if any(phrase in answer.lower() for phrase in forbidden_phrases):
                logger.warning(f"–ù–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç Ollama: {answer}")
                return None
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
            if len(answer.split()) > 4:
                logger.warning(f"–û—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π: {answer}")
                return None
                
            # –°—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —è–∑—ã–∫–∞
            if model_config.language == "ru":
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å —Ä—É—Å—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ –Ω–µ—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –±—É–∫–≤
                has_cyrillic = any(1040 <= ord(c) <= 1279 for c in answer)
                has_latin = any(c.isalpha() and ord(c) < 1024 for c in answer if c not in ' !?.,üòäüòâüòçüòòüíïüî•')
                if not has_cyrillic or has_latin:
                    logger.warning(f"–û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞: {answer}")
                    return None
            else:  # English
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ—Ç —Ä—É—Å—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
                if any(1040 <= ord(c) <= 1279 for c in answer):
                    logger.warning(f"–û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä—É—Å—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞: {answer}")
                    return None
                    
            return answer
    except Exception as e:
        logger.warning(f"Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    
    return None

def parse_spin_syntax(text: str) -> str:
    """–ü–∞—Ä—Å–∏–Ω–≥ —Å–ø–∏–Ω—Ç–∞–∫—Å–∞ –≤–∏–¥–∞ {–≤–∞—Ä–∏–∞–Ω—Ç1|–≤–∞—Ä–∏–∞–Ω—Ç2|–≤–∞—Ä–∏–∞–Ω—Ç3}"""
    logger.debug(f"Parsing spin syntax for text: {text}")
    spin_regex = r'{([^}]+)}'
    def replace_spin(match):
        options = [opt.strip() for opt in match.group(1).split('|')]
        return random.choice(options)
    parsed_text = re.sub(spin_regex, replace_spin, text)
    logger.debug(f"Parsed text: {parsed_text}")
    return parsed_text

async def generate_ai_response(message: str, model_config: ModelConfig, conversation_state: dict, model_name: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ò–ò —Å—Ç—Ä–æ–≥–æ –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º –º–æ–¥–µ–ª–∏"""
    logger.info(f"Generating response for message: '{message}', model: '{model_name}' (display: '{model_config.name}'), language: '{model_config.language}'")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç—Ä–∏–≥–≥–µ—Ä—ã –¥–ª—è –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–≥–æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    message_lower = message.lower().strip()
    for trigger in model_config.triggers:
        if trigger.lower().strip() in message_lower:
            logger.info(f"Trigger '{trigger}' detected! Returning final message immediately.")
            return parse_spin_syntax(model_config.final_message)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∏–≥ –ª–∏ –¥–∏–∞–ª–æ–≥ –ø—Ä–µ–¥–ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    if conversation_state["message_count"] == model_config.message_count - 1:
        logger.info("Returning semi_message")
        return parse_spin_syntax(model_config.semi_message)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∏–≥ –ª–∏ –¥–∏–∞–ª–æ–≥ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    if conversation_state["message_count"] >= model_config.message_count:
        logger.info("Returning final_message")
        return parse_spin_syntax(model_config.final_message)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—É—á–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
    logger.info(f"Searching for trained response with model name: '{model_name}'")
    trained_response = await get_trained_response(message, model_name)
    if trained_response:
        logger.info(f"Found trained response: '{trained_response}'")
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∏–º–µ–Ω—è–µ–º parse_spin_syntax –∫ –æ–±—É—á–µ–Ω–Ω–æ–º—É –æ—Ç–≤–µ—Ç—É
        parsed_response = parse_spin_syntax(trained_response)
        logger.info(f"Parsed trained response: '{parsed_response}'")
        return parsed_response
    else:
        logger.warning(f"No trained response found, trying Ollama...")
    
    # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç Ollama
    ollama_response = await get_ollama_response(message, model_config)
    if ollama_response:
        logger.info(f"Got Ollama response: '{ollama_response}'")
        return parse_spin_syntax(ollama_response)
    else:
        logger.warning(f"Ollama unavailable, using default logic")
    
    # –ë–∞–∑–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ –°–¢–†–û–ì–û –ø–æ —è–∑—ã–∫—É –º–æ–¥–µ–ª–∏
    if model_config.language == "ru":
        responses = {
            "greetings": ["–ü—Ä–∏–≤–µ—Ç, –∫—Ä–∞—Å–∞–≤—á–∏–∫! üòä", "–ü—Ä–∏–≤–µ—Ç–∏–∫! üòò", "–•–∞–π, –∫–∞–∫ –¥–µ–ª–∞? üòâ", "–ü—Ä–∏–≤–µ—Ç –º–∏–ª—ã–π! üíï", "–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é! üòç"],
            "age_questions": [f"{model_config.age}, –∞ —Ç–µ–±–µ? üòâ", "–Æ–Ω–∞—è, –∞ —Ç—ã? üòò", "–í–æ–∑—Ä–∞—Å—Ç ‚Äî —Å–µ–∫—Ä–µ—Ç! üòç", f"–ú–Ω–µ {model_config.age}! üíï", "–ú–æ–ª–æ–¥–∞—è! üòä"],
            "location_questions": [f"–ò–∑ {model_config.city}! üòç", f"{model_config.city}, —Ç—ã –≥–¥–µ? üòâ", f"{model_config.country}! üíï", f"–ñ–∏–≤—É –≤ {model_config.city}! üòä"],
            "flirty": ["–û–≥–æ, —Å–º–µ–ª–æ! üòè", "–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ, –ø—Ä–æ–¥–æ–ª–∂–∞–π! üòâ", "–¢—ã –∏–Ω—Ç—Ä–∏–≥—É–µ—à—å! üòç", "–ñ–∞—Ä–∫–æ –≥–æ–≤–æ—Ä–∏—à—å! üî•", "–°–º–µ–ª—ã–π –∫–∞–∫–æ–π! üòò"],
            "default": ["–ö—Ä—É—Ç–æ! üòä", "–°–µ—Ä—å—ë–∑–Ω–æ? üòâ", "–†–∞—Å—Å–∫–∞–∂–∏ –µ—â—ë! üòç", "–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ! üíï", "–û–≥–æ! üòò", "–ó–¥–æ—Ä–æ–≤–æ! üî•"]
        }
    else:  # English
        responses = {
            "greetings": ["Hey handsome! üòä", "Hi there! üòò", "Yo, what's up? üòâ", "Hello cutie! üíï", "Hi gorgeous! üòç"],
            "age_questions": [f"{model_config.age}, you? üòâ", "Young, you? üòò", "Age's a secret! üòç", f"I'm {model_config.age}! üíï", "Young! üòä"],
            "location_questions": [f"From {model_config.city}! üòç", f"{model_config.city}, you? üòâ", f"{model_config.country}! üíï", f"Live in {model_config.city}! üòä"],
            "flirty": ["Oh, naughty! üòè", "Keep talking! üòâ", "You're intriguing! üòç", "Hot talk! üî•", "Bold boy! üòò"],
            "default": ["Cool! üòä", "Really? üòâ", "Tell me more! üòç", "Interesting! üíï", "Wow! üòò", "Great! üî•"]
        }
    
    # –í—ã–±–∏—Ä–∞–µ–º –æ—Ç–≤–µ—Ç—ã –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —è–∑—ã–∫–∞ –º–æ–¥–µ–ª–∏
    lang_responses = responses
    
    if any(word in message_lower for word in ["–ø—Ä–∏–≤–µ—Ç", "hi", "hey", "hello", "—Ö–∞–π"]):
        response = random.choice(lang_responses["greetings"])
        logger.info(f"Generated greeting response: '{response}'")
    elif any(word in message_lower for word in ["—Å–∫ –ª–µ—Ç", "age", "—Å–∫–æ–ª—å–∫–æ –ª–µ—Ç", "how old", "–≤–æ–∑—Ä–∞—Å—Ç"]):
        response = random.choice(lang_responses["age_questions"])
        logger.info(f"Generated age response: '{response}'")
    elif any(word in message_lower for word in ["–æ—Ç–∫—É–¥–∞", "from", "–≥–æ—Ä–æ–¥", "where", "city"]):
        response = random.choice(lang_responses["location_questions"])
        logger.info(f"Generated location response: '{response}'")
    elif any(word in message_lower for word in ["—à–∞–ª–∏—Ç—å", "horny", "—Ö–æ—á—É", "want", "m or f", "naughty", "—Å–µ–∫—Å"]):
        response = random.choice(lang_responses["flirty"])
        logger.info(f"Generated flirty response: '{response}'")
    else:
        response = random.choice(lang_responses["default"])
        logger.info(f"Generated default response: '{response}'")
    
    # –î–æ–±–∞–≤–ª—è–µ–º —ç–º–æ–¥–∑–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if model_config.use_emoji and not any(emoji in response for emoji in ["üòò", "üòä", "üòâ", "üíï", "üî•", "üòç"]):
        emojis = ["üòò", "üòä", "üòâ", "üíï", "üî•", "üòç"]
        response += f" {random.choice(emojis)}"
    
    return parse_spin_syntax(response)

async def get_trained_response(message: str, model: str) -> Optional[str]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–µ–π"""
    message_lower = message.lower().strip()
    logger.debug(f"Checking trained response for message: '{message}', model: '{model}'")
    
    exact_match = await db.trained_responses.find_one({
        "question": message_lower,
        "model": model
    }, sort=[("priority", -1)])
    if exact_match:
        logger.info(f"Found exact match for '{message}' with priority {exact_match.get('priority', 1)}")
        return exact_match["answer"]
    
    words = message_lower.split()
    for word in words:
        if len(word) > 3:
            responses = await db.trained_responses.find({
                "question": {"$regex": word, "$options": "i"},
                "model": model
            }).sort([("priority", -1)]).limit(5).to_list(length=None)
            
            if responses:
                best_response = responses[0]
                logger.info(f"Found keyword match for '{message}' using word '{word}' with priority {best_response.get('priority', 1)}")
                return best_response["answer"]
    
    partial_matches = await db.trained_responses.find({
        "question": {"$regex": message_lower, "$options": "i"},
        "model": model
    }).sort([("priority", -1)]).limit(3).to_list(length=None)
    
    if partial_matches:
        best_match = partial_matches[0]
        logger.info(f"Found partial match for '{message}' with priority {best_match.get('priority', 1)}")
        return best_match["answer"]
    
    logger.info(f"No trained response found for '{message}'")
    return None

# API Endpoints
@api_router.get("/")
async def root():
    logger.debug("Received request to /api/")
    return {"message": "AI Sexter Bot API v2.0"}

@api_router.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """–û—Å–Ω–æ–≤–Ω–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è —á–∞—Ç–∞"""
    logger.debug(f"Received chat request: {request.model_dump()}")
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –°–¢–†–û–ì–û –∏–∑ JSON —Ñ–∞–π–ª–∞
        model_config = await load_model(request.model)
        
        conversation_state = get_conversation_state(request.user_id, request.model)
        conversation_state["message_count"] += 1
        conversation_state["last_activity"] = datetime.now(dt.UTC)
        conversation_state["messages"].append({
            "user_message": request.message,
            "timestamp": datetime.now(dt.UTC)
        })
        
        ai_response = await generate_ai_response(request.message, model_config, conversation_state, request.model)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        await db.bot_activities.insert_one({
            "model": request.model,
            "action": "chat_response",
            "user_message": request.message,
            "ai_response": ai_response,
            "timestamp": datetime.now(dt.UTC)
        })
        
        # Check if trigger was detected (response equals final_message)
        trigger_detected = ai_response == parse_spin_syntax(model_config.final_message)
        
        is_semi = conversation_state["message_count"] == model_config.message_count - 1 and not trigger_detected
        is_last = conversation_state["message_count"] >= model_config.message_count or trigger_detected
        
        await db.conversations.insert_one({
            "user_id": request.user_id,
            "model": request.model,
            "user_message": request.message,
            "ai_response": ai_response,
            "message_number": conversation_state["message_count"],
            "is_semi": is_semi,
            "is_last": is_last,
            "emotion": detect_emotion(request.message),
            "timestamp": datetime.now(dt.UTC)
        })
        
        return ChatResponse(
            response=ai_response,
            message_number=conversation_state["message_count"],
            is_semi=is_semi,
            is_last=is_last,
            emotion=detect_emotion(request.message),
            model_used=request.model
        )
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ chat: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/test")
async def test_chat(request: TestRequest):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    logger.debug(f"Received test request: {request.model_dump()}")
    try:
        model_config = await load_model(request.model)
        temp_state = {"message_count": 1, "messages": []}
        response = await generate_ai_response(request.message, model_config, temp_state, request.model)
        
        return {
            "response": response,
            "model": request.model,
            "emotion": detect_emotion(request.message)
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ test: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/rate")
async def rate_response(request: RatingRequest):
    """–û—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–±—É—á–µ–Ω–∏–µ–º –ø—Ä–∏ –≤—ã—Å–æ–∫–∏—Ö –æ—Ü–µ–Ω–∫–∞—Ö"""
    logger.debug(f"Received rate request: {request.model_dump()}")
    try:
        await db.ratings.insert_one({
            "user_id": request.user_id,
            "model": request.model,
            "message": request.message,
            "response": request.response,
            "rating": request.rating,
            "timestamp": datetime.now(dt.UTC)
        })
        
        await db.statistics.update_one(
            {"type": "ratings", "model": request.model},
            {
                "$inc": {"total_ratings": 1, "total_score": request.rating},
                "$set": {"updated_at": datetime.now(dt.UTC)}
            },
            upsert=True
        )
        
        if request.rating >= 8:
            await db.trained_responses.update_one(
                {"question": request.message.lower().strip(), "model": request.model},
                {
                    "$set": {
                        "answer": request.response,
                        "priority": request.rating,
                        "auto_trained": True,
                        "updated_at": datetime.now(dt.UTC)
                    }
                },
                upsert=True
            )
            logger.info(f"Auto-trained response for '{request.message}' with rating {request.rating}")
        
        return {"message": "–†–µ–π—Ç–∏–Ω–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω" + (" –∏ –æ—Ç–≤–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ–±—É—á–µ–Ω–∏–µ" if request.rating >= 8 else "")}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ rate: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/train")
async def train_model(request: TrainingRequest):
    """–†—É—á–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    logger.debug(f"Received train request: {request.model_dump()}")
    try:
        await db.trained_responses.update_one(
            {"question": request.question.lower().strip(), "model": request.model},
            {
                "$set": {
                    "answer": request.answer,
                    "priority": request.priority,
                    "updated_at": datetime.now(dt.UTC)
                }
            },
            upsert=True
        )
        
        return {"message": "–û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã"}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ train: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/train-file")
async def train_from_file(model: str, file: UploadFile = File(...)):
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –æ–±—É—á–µ–Ω–∏—è"""
    try:
        content = await file.read()
        content = content.decode('utf-8')
        
        lines = content.split('\n')
        processed = 0
        
        for line in lines:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
                
            # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π
            separators = [' - ', ' | ', '\t']
            question, answer = None, None
            
            for sep in separators:
                if sep in line:
                    parts = line.split(sep, 1)
                    if len(parts) == 2:
                        question = parts[0].strip()
                        answer = parts[1].strip()
                        break
            
            if question and answer:
                await db.trained_responses.update_one(
                    {"question": question.lower(), "model": model},
                    {
                        "$set": {
                            "answer": answer,
                            "priority": 5,
                            "file_trained": True,
                            "updated_at": datetime.now(dt.UTC)
                        }
                    },
                    upsert=True
                )
                processed += 1
        
        return {"message": f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed} –∑–∞–ø–∏—Å–µ–π –∏–∑ —Ñ–∞–π–ª–∞"}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/models")
async def get_models():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    logger.debug("Received request to /api/models")
    try:
        models = []
        for model_file in MODELS_DIR.glob("*.json"):
            model_name = model_file.stem
            try:
                model_config = await load_model(model_name)
                models.append({
                    "name": model_name,
                    "display_name": model_config.name,
                    "language": model_config.language,
                    "country": model_config.country
                })
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
        
        return {"models": models}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ get_models: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/model/{model_name}")
async def get_model(model_name: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏"""
    logger.debug(f"Received request to /api/model/{model_name}")
    try:
        model_config = await load_model(model_name)
        return model_config.model_dump()
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ get_model: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/model/{model_name}")
async def save_model_config(model_name: str, config: ModelConfig):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏"""
    logger.debug(f"Received request to save model: {model_name}")
    try:
        await save_model(model_name, config)
        return {"message": f"–ú–æ–¥–µ–ª—å {model_name} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞"}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ save_model_config: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/statistics")
async def get_statistics():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã"""
    logger.debug("Received request to /api/statistics")
    try:
        total_conversations = await db.conversations.count_documents({})
        total_users = len(await db.conversations.distinct("user_id"))
        
        models_stats = await db.conversations.aggregate([
            {"$group": {
                "_id": "$model",
                "conversations": {"$sum": 1},
                "avg_rating": {"$avg": "$rating"}
            }}
        ]).to_list(length=None)
        
        top_responses = await db.conversations.aggregate([
            {"$group": {
                "_id": "$ai_response",
                "count": {"$sum": 1}
            }},
            {"$sort": {"count": -1}},
            {"$limit": 10}
        ]).to_list(length=None)
        
        top_questions = await db.conversations.aggregate([
            {"$group": {
                "_id": "$user_message",
                "count": {"$sum": 1}
            }},
            {"$sort": {"count": -1}},
            {"$limit": 10}
        ]).to_list(length=None)
        
        ratings_stats = await db.ratings.aggregate([
            {"$group": {
                "_id": "$model",
                "avg_rating": {"$avg": "$rating"},
                "total_ratings": {"$sum": 1}
            }}
        ]).to_list(length=None)
        
        problem_questions = await db.ratings.find(
            {"rating": {"$lte": 3}},
            {"message": 1, "response": 1, "rating": 1, "model": 1}
        ).limit(10).to_list(length=None)
        
        return {
            "total_conversations": total_conversations,
            "total_users": total_users,
            "models_stats": models_stats,
            "top_responses": top_responses,
            "top_questions": top_questions,
            "ratings_stats": ratings_stats,
            "problem_questions": problem_questions,
            "system_status": {
                "database_connected": True,
                "models_loaded": len(loaded_models),
                "active_conversations": len(conversation_states)
            }
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ statistics: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/statistics/{model_name}")
async def get_model_statistics(model_name: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    logger.debug(f"Received request to /api/statistics/{model_name}")
    try:
        total_conversations = await db.conversations.count_documents({"model": model_name})
        total_users = len(await db.conversations.distinct("user_id", {"model": model_name}))
        
        top_responses = await db.conversations.aggregate([
            {"$match": {"model": model_name}},
            {"$group": {
                "_id": "$ai_response",
                "count": {"$sum": 1}
            }},
            {"$sort": {"count": -1}},
            {"$limit": 10}
        ]).to_list(length=None)
        
        top_questions = await db.conversations.aggregate([
            {"$match": {"model": model_name}},
            {"$group": {
                "_id": "$user_message",
                "count": {"$sum": 1}
            }},
            {"$sort": {"count": -1}},
            {"$limit": 10}
        ]).to_list(length=None)
        
        avg_rating = await db.ratings.aggregate([
            {"$match": {"model": model_name}},
            {"$group": {
                "_id": None,
                "avg_rating": {"$avg": "$rating"},
                "total_ratings": {"$sum": 1}
            }}
        ]).to_list(length=None)
        
        rating_info = avg_rating[0] if avg_rating else {"avg_rating": 0, "total_ratings": 0}
        
        problem_questions = await db.ratings.find(
            {"model": model_name, "rating": {"$lte": 3}},
            {"message": 1, "response": 1, "rating": 1}
        ).limit(10).to_list(length=None)
        
        trained_count = await db.trained_responses.count_documents({"model": model_name})
        
        return {
            "model": model_name,
            "total_conversations": total_conversations,
            "total_users": total_users,
            "avg_rating": rating_info["avg_rating"],
            "total_ratings": rating_info["total_ratings"],
            "trained_responses": trained_count,
            "top_responses": top_responses,
            "top_questions": top_questions,
            "problem_questions": problem_questions
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ model statistics: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.delete("/statistics/{model_name}")
async def clear_model_statistics(model_name: str):
    """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –æ–±—É—á–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤"""
    logger.debug(f"Received request to clear statistics for model: {model_name}")
    try:
        # –£–¥–∞–ª—è–µ–º –¥–∏–∞–ª–æ–≥–∏
        conversations_deleted = await db.conversations.delete_many({"model": model_name})
        
        # –£–¥–∞–ª—è–µ–º —Ä–µ–π—Ç–∏–Ω–≥–∏
        ratings_deleted = await db.ratings.delete_many({"model": model_name})
        
        # –£–¥–∞–ª—è–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        activities_deleted = await db.bot_activities.delete_many({"model": model_name})
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats_deleted = await db.statistics.delete_many({"model": model_name})
        
        # –ù–ï –£–î–ê–õ–Ø–ï–ú trained_responses - –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –æ—Å—Ç–∞—Ç—å—Å—è!
        
        return {
            "message": f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏ {model_name} –æ—á–∏—â–µ–Ω–∞",
            "deleted": {
                "conversations": conversations_deleted.deleted_count,
                "ratings": ratings_deleted.deleted_count,
                "activities": activities_deleted.deleted_count,
                "statistics": stats_deleted.deleted_count
            },
            "preserved": {
                "trained_responses": "—Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã"
            }
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/settings")
async def get_settings():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫"""
    logger.debug("Received request to /api/settings")
    try:
        settings = await db.user_settings.find_one({"type": "global_settings"})
        if settings:
            settings.pop("_id", None)
            settings.pop("type", None)
            return settings
        else:
            return {"default_model": "", "auto_save": True}
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ get_settings: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/settings")
async def save_settings(settings: dict):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫"""
    logger.debug(f"Received request to save settings: {settings}")
    try:
        await db.user_settings.update_one(
            {"type": "global_settings"},
            {
                "$set": {
                    **settings,
                    "updated_at": datetime.now(dt.UTC)
                }
            },
            upsert=True
        )
        
        return {"message": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã", "status": "success"}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ save_settings: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã"""
    logger.debug("Received request to /api/health")
    try:
        await db.command("ping")
        db_status = True
    except:
        db_status = False
    
    return {
        "status": "healthy" if db_status else "unhealthy",
        "database": db_status,
        "models_loaded": len(loaded_models),
        "active_conversations": len(conversation_states),
        "timestamp": datetime.now(dt.UTC)
    }

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ api_router –∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é
app.include_router(api_router)

# –§—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –æ–±—É—á–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ (–ù–ï –°–û–ó–î–ê–ï–ú –ú–û–î–ï–õ–ò!)
@app.on_event("startup")
async def add_more_trained_responses():
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –æ–±—É—á–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è"""
    logger.info("Adding more trained responses for variety...")
    
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è —Ä—É—Å—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π
    russian_responses = [
        {"question": "–ø—Ä–∏–≤–µ—Ç", "answer": "{–ü—Ä–∏–≤–µ—Ç–∏–∫ –∫—Ä–∞—Å–∞–≤—á–∏–∫!|–•–∞–π –º–∏–ª—ã–π!|–ü—Ä–∏–≤–µ—Ç —Å–æ–ª–Ω—ã—à–∫–æ!|–ü—Ä–∏–≤–µ—Ç–∏–∫ –¥–æ—Ä–æ–≥–æ–π!} üòä", "model": "rus_girl_1", "priority": 10},
        {"question": "–∫–∞–∫ –¥–µ–ª–∞", "answer": "{–û—Ç–ª–∏—á–Ω–æ, –æ—Å–æ–±–µ–Ω–Ω–æ —Å —Ç–æ–±–æ–π!|–°—É–ø–µ—Ä, –∞ —É —Ç–µ–±—è –∫–∞–∫?|–í—Å–µ –∫—Ä—É—Ç–æ, —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–π –æ —Å–µ–±–µ!|–ó–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ!} üòâ", "model": "rus_girl_1", "priority": 9},
        {"question": "—á—Ç–æ –¥–µ–ª–∞–µ—à—å", "answer": "{–°–∫—É—á–∞—é... –ê —Ç—ã?|–î—É–º–∞—é –æ –ø—Ä–∏—è—Ç–Ω–æ–º|–û—Ç–¥—ã—Ö–∞—é –¥–æ–º–∞|–ñ–¥—É –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–≥–æ –æ–±—â–µ–Ω–∏—è} üòä", "model": "rus_girl_1", "priority": 8},
        {"question": "—Ç—ã –∫—Ä–∞—Å–∏–≤–∞—è", "answer": "{–°–ø–∞—Å–∏–±–æ –º–∏–ª—ã–π!|–¢—ã —Ç–∞–∫–æ–π –≥–∞–ª–∞–Ω—Ç–Ω—ã–π!|–¢—ã —Ç–æ–∂–µ —Å–∏–º–ø–∞—Ç–∏—á–Ω—ã–π!|–ü—Ä–∏—è—Ç–Ω–æ —Å–ª—ã—à–∞—Ç—å!} üòò", "model": "rus_girl_1", "priority": 9},
        {"question": "—Ö–æ—á—É –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è", "answer": "{–î–∞–≤–∞–π –∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è!|–Ø —Ç–æ–∂–µ —Ö–æ—á—É!|–ë—É–¥–µ–º –¥—Ä—É–∑—å—è–º–∏?|–° —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏–µ–º!} üíï", "model": "rus_girl_1", "priority": 8},
        
        {"question": "–ø—Ä–∏–≤–µ—Ç", "answer": "{–ü—Ä–∏–≤–µ—Ç–∏–∫!|–•–∞–π!|–ü—Ä–∏–≤–µ—Ç –¥–æ—Ä–æ–≥–æ–π!|–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π –º–∏–ª—ã–π!} üòä", "model": "rus_girl_2", "priority": 10},
        {"question": "–∫–∞–∫ –¥–µ–ª–∞", "answer": "{–•–æ—Ä–æ—à–æ, –∞ —É —Ç–µ–±—è?|–í—Å–µ –æ—Ç–ª–∏—á–Ω–æ!|–ü—Ä–µ–∫—Ä–∞—Å–Ω–æ!|–ó–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ!} üòâ", "model": "rus_girl_2", "priority": 9},
        {"question": "—á—Ç–æ –¥–µ–ª–∞–µ—à—å", "answer": "{–ß–∏—Ç–∞—é|–°–ª—É—à–∞—é –º—É–∑—ã–∫—É|–ì–æ—Ç–æ–≤–ª—é|–û—Ç–¥—ã—Ö–∞—é} üòä", "model": "rus_girl_2", "priority": 8},
    ]
    
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π
    english_responses = [
        {"question": "hey", "answer": "{Hey cutie!|Hi handsome!|Hello there!|Hey gorgeous!} üíï", "model": "eng_girl_1", "priority": 10},
        {"question": "how are you", "answer": "{Great, you?|Amazing!|Fantastic!|Perfect!} üòâ", "model": "eng_girl_1", "priority": 9},
        {"question": "what are you doing", "answer": "{Missing you|Thinking of you|Just relaxing|Waiting for you} üòä", "model": "eng_girl_1", "priority": 8},
        {"question": "you're beautiful", "answer": "{Thank you babe!|You're sweet!|So are you!|Aww thanks!} üòò", "model": "eng_girl_1", "priority": 9},
        {"question": "wanna chat", "answer": "{Of course!|Always!|Sure thing!|Let's talk!} üíï", "model": "eng_girl_1", "priority": 8},
        
        {"question": "hey", "answer": "{Hi there!|Hello!|Hey babe!|Hi cutie!} üíï", "model": "eng_girl_1_joingy", "priority": 10},
        {"question": "how are you", "answer": "{Great!|Amazing!|Perfect!|Wonderful!} üòâ", "model": "eng_girl_1_joingy", "priority": 9},
        {"question": "what are you doing", "answer": "{Relaxing|Waiting for you|Just chilling|Having fun} üòä", "model": "eng_girl_1_joingy", "priority": 8},
    ]
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –æ—Ç–≤–µ—Ç—ã
    all_responses = russian_responses + english_responses
    
    for response in all_responses:
        await db.trained_responses.update_one(
            {"question": response["question"], "model": response["model"]},
            {
                "$set": {
                    "answer": response["answer"],
                    "priority": response["priority"],
                    "startup_added": True,
                    "updated_at": datetime.now(dt.UTC)
                }
            },
            upsert=True
        )
        logger.info(f"Added enhanced response for '{response['question']}' in model '{response['model']}'")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)